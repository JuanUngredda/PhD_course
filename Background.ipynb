{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e821d8d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider, Layout\n",
    "import ipywidgets as widgets\n",
    "from scipy.stats import norm\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4db246",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7bab6d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "def hide_toggle(for_next=False):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    toggle_text = 'Toggle show/hide'  # text shown on toggle link\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        toggle_text += ' next cell'\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139db5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian processes\n",
    "\n",
    "<br>\n",
    "PhD. Juan Ungredda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbbef41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* Multivariate Gaussian Distribution\n",
    "* Gaussian process\n",
    "* Gaussian process regression\n",
    "* Hyperparameter optimization\n",
    "* Difficulties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0583f0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Univariate Gaussian Density\n",
    "\n",
    "A random variable $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$ presents a density function\n",
    "\n",
    "$$\n",
    "f_x(x) = \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left( -\\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x$ is the random variable.\n",
    "- $\\mu$ is the mean, representing the central tendency of the distribution.\n",
    "- $\\sigma^2$ is the variance, determining the spread or dispersion of the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91418a97",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_gaussians(mu, var):\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    x = np.linspace(-3.5,\n",
    "                3.5, 100)\n",
    "    y = norm.pdf(x)\n",
    "    standard_normal = pd.DataFrame({\"x\": x, \"z(x)\": y})\n",
    "    sn.lineplot(data = standard_normal, x=\"x\", y=\"z(x)\",label=\"$\\mathcal{N}(0,1)$\")\n",
    "    y = norm.pdf(x, mu, np.sqrt(var))\n",
    "    non_standard_normal = pd.DataFrame({\"x\": x, \"f(x)\": y})\n",
    "    sn.lineplot(data = non_standard_normal, x=\"x\",  y=\"f(x)\", label=\"$\\mathcal{N}( %s, %s )$\" % (mu,var))\n",
    "    plt.ylabel(r'$f_x$', size=font_size)\n",
    "    plt.xlabel(r\"$X$\", size=font_size)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43742bab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12818535854579408681() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12818535854579408681()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5c93a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d586ba7264c4a978837099b25a0cb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='$\\\\mu$:', layout=Layout(width='50%'), max=5.0, min=-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget = interact(plot_gaussians,\n",
    "         mu=FloatSlider(value=0, min=-5, max=5, step=1, description=\"$\\mu$:\", layout=Layout(width='50%')),\n",
    "         var=FloatSlider(value=1, min=0.1, max=5, step=1, description='$\\sigma^2$:', layout=Layout(width='50%')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84876dcf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multivariate Gaussian Distribution\n",
    "\n",
    "A random variable $x \\sim \\mathcal{N}( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ presents a density function\n",
    "\n",
    "$$ f_x(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu})\\right) $$\n",
    "\n",
    "Where:\n",
    "- $ \\mathbf{x} $ is a $ d $-dimensional vector representing the random variables.\n",
    "- $ \\boldsymbol{\\mu} $ is the mean vector, representing the expected value of each random variable.\n",
    "- $ \\boldsymbol{\\Sigma} $ is the covariance matrix, representing the relationships between the random variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05fcc8c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_gaussian_density(mu1, mu2, var_x1, var_x2, cov):\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    mu = [mu1, mu2]  # mean\n",
    "    Sigma = [[var_x1, cov], [cov, var_x2]]  # covariance matrix\n",
    "    # Generate grid points for x and y\n",
    "    x = np.linspace(-3.5, 3.5, 100)\n",
    "    y = np.linspace(-3.5, 3.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate the bivariate normal PDF for each pair of (x, y) values\n",
    "    pos = np.dstack((X, Y))\n",
    "    Z = multivariate_normal.pdf(pos, mean=mu, cov=Sigma)\n",
    "    \n",
    "    # Plot bivariate normal PDF\n",
    "    plt.contour(X, Y, Z)\n",
    "    \n",
    "    plt.xlabel('$X_1$', size=font_size)\n",
    "    plt.ylabel('$X_2$', size=font_size)\n",
    "    plt.title('Bivariate Normal Distribution')\n",
    "\n",
    "def plot_gaussian_density(mu1, mu2, var_x1, var_x2, cov):\n",
    "    plot_2d_gaussian_density(mu1, mu2, var_x1, var_x2, cov)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cd1bb46",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3524732500280080183() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3524732500280080183()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93638723",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153f57e7c4d0466ba56082ab9e5b2c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='$\\\\mu_1$:', layout=Layout(width='50%'), max=5.0, min…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget = interact(plot_gaussian_density,\n",
    "         mu1=FloatSlider(value=0, min=-5, max=5, step=1, description='$\\mu_1$:', layout=Layout(width='50%')),\n",
    "         mu2=FloatSlider(value=0, min=-5, max=5, step=1, description='$\\mu_2$:', layout=Layout(width='50%')),\n",
    "         var_x1=FloatSlider(value=1, min=0.1, max=5, step=0.1, description='$Var(x_1)$:', layout=Layout(width='50%')),\n",
    "         var_x2=FloatSlider(value=1, min=0.1, max=5, step=0.1, description='$Var(x_2)$:', layout=Layout(width='50%')),\n",
    "         cov=FloatSlider(value=0.5, min=-5, max=5, step=0.1, description='$Cov(x_1, x_2)$:', layout=Layout(width='50%')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad0a91-7c1a-42e0-889b-dae5b8338b80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Covariance Matrix\n",
    "\n",
    "For $ n $ random variables $ X_1, X_2, \\ldots, X_n $, the multivariate covariance matrix $ \\Sigma $ is defined as:\n",
    "\n",
    "$$\n",
    "\\Sigma = \\begin{bmatrix} \n",
    "\\text{Var}(x_1) & \\text{Cov}(x_1, x_2) & \\ldots & \\text{Cov}(x_1, x_n) \\\\\n",
    "\\text{Cov}(x_2, x_1) & \\text{Var}(x_2) & \\ldots & \\text{Cov}(x_2, x_n) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(x_n, x_1) & \\text{Cov}(x_n, x_2) & \\ldots & \\text{Var}(x_n)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A covariance matrix $\\Sigma$ must satisfy the following properties:\n",
    "\n",
    "1. **Symmetry**: $ \\text{cov}(x, x') = \\text{cov}(x', x) $ for all $ x $ and $ x' $.\n",
    "2. **Positive Semi-definiteness**: For any finite collection of points $ x_1, x_2, \\ldots, x_n $, the covariance matrix $ \\Sigma $ defined by $ \\Sigma_{ij} = \\text{cov}(x_i, x_j) $ is positive semi-definite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b73e76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Positive Semi-Definite Matrix and Covariance Matrix\n",
    "\n",
    "#### Quadratic Form\n",
    "\n",
    "A quadratic form is a homogeneous polynomial of degree two in a number of variables. The quadratic form associated with a matrix $A$ and a vector $x$ is given by \n",
    "\n",
    "$$x^T A x$$\n",
    "\n",
    "- **Postive semi-definite**: $x^T A x \\geq 0$ for any vector $x \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce38c88",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: Positive Semi-Definite Matrix and Covariance Matrix\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Part a** Prove that every covariance matrix is positive-semidefinite.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Part b** Show that the following matrix is not positive-semidefinite $$\n",
    "\\begin{bmatrix}\n",
    "1 & -2 \\\\\n",
    "-2 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "**Part a**:\n",
    "\n",
    "$$\n",
    "Q(y) = y^T \\Sigma y = y^T \\mathbb{E}[(\\mathbf{x} -\\mathbf{\\mu})(\\mathbf{x} -\\mathbf{\\mu})^T ]y = \\text{Var}[y^T (\\mathbf{X} - \\boldsymbol{\\mu})] \\geq 0 \n",
    "$$\n",
    "\n",
    "**Part b**: consider $\\mathbf{x} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}$ or $\\mathbf{x} = \\begin{bmatrix}\n",
    "-1 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e5ee9a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define symbolic variables\n",
    "x, y = sp.symbols('x y')\n",
    "\n",
    "# Define a grid of points\n",
    "x_vals = np.linspace(-3, 3, 100)\n",
    "y_vals = np.linspace(-3, 3, 100)\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "Z = np.zeros_like(X)\n",
    "\n",
    "# Function to update matrix values\n",
    "def update_matrix(a11,a22, a12, a21,):\n",
    "    A = np.array([[a11,a12], [a21, a22]])\n",
    "    update_plot(A)\n",
    "\n",
    "\n",
    "# Define the quadratic form equation\n",
    "def quadratic_form(A):\n",
    "    return sp.expand((sp.Matrix([x, y]).T @ sp.Matrix(A) @ sp.Matrix([x, y]))[0])\n",
    "\n",
    "# Function to update plot\n",
    "def update_plot(A):\n",
    "    Z = np.zeros_like(X)\n",
    "    for i in range(len(x_vals)):\n",
    "        for j in range(len(y_vals)):\n",
    "            vec = np.array([X[i, j], Y[i, j]])\n",
    "            Z[i, j] = np.dot(vec.T, np.dot(np.array(A), vec))\n",
    "\n",
    "    # Plot the result using contour plot in Matplotlib\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contour(X, Y, Z, levels=[1, 2, 3, 4, 5])  # Change levels as needed\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "\n",
    "    # Include the quadratic form equation in the title with LaTeX formatting\n",
    "    plt.title(r'Quadratic Form: $' + sp.latex(quadratic_form(A)) + r'$')\n",
    "\n",
    "    # Print the current matrix values inside the plot\n",
    "    matrix_text = np.array2string(A, formatter={'float_kind':lambda x: \"{:.1f}\".format(x)})\n",
    "    plt.text(0.05, 0.95, r'Matrix values:', fontsize=12, transform=plt.gca().transAxes)\n",
    "    plt.text(0.05, 0.85, matrix_text, fontsize=12, transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb00bcaa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_3644550489705904493() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_3644550489705904493()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea54cb5",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141f019f08414aa3bc8dead4bce1a3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatText(value=1.0, description='$A_{11}$', layout=Layout(width='50%')), FloatText(valu…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text input widgets for matrix values\n",
    "a11_text = widgets.FloatText(value=1, description=r'$A_{11}$', layout=Layout(width='50%'))\n",
    "a22_text = widgets.FloatText(value=1, description=r'$A_{22}$', layout=Layout(width='50%'))\n",
    "a12_text = widgets.FloatText(value=0, description=r'$A_{12}$', layout=Layout(width='50%'))\n",
    "a21_text = widgets.FloatText(value=0, description=r'$A_{21}$', layout=Layout(width='50%'))\n",
    "\n",
    "\n",
    "# Use interact to link the text input widgets with the update_matrix function\n",
    "widgets.interactive(update_matrix, a11=a11_text, a22=a22_text, a21=a21_text, a12=a12_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b665b72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditioning\n",
    "\n",
    "<br>\n",
    "Given the two random vectors $\\mathbf{x}_{A}$ and $\\mathbf{x}_{B}$, the conditional probability of $\\mathbf{x}_{A}$ is defined as,\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{A}|\\mathbf{x}_{B}) = \\frac{p(\\mathbf{x}_{A}, \\mathbf{x}_{B})}{p(\\mathbf{x}_{B})}\n",
    "$$\n",
    "\n",
    "defined for $p(\\mathbf{x}_{B}) > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51d736",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise: Gaussian Conditioning\n",
    "\n",
    "Assume an n-dimensional random vector has a normal distribution,\n",
    "\n",
    "$$\n",
    "N(\\left[\\begin{array}{c}\n",
    "{\\bf x} \\\\\n",
    "{\\bf y}\n",
    "\\end{array}\\right], \\left[\\begin{array}{c}\n",
    "\\mu_X \\\\\n",
    "\\mu_Y\n",
    "\\end{array}\\right], \\left[\\begin{array}{cc}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{array}\\right]) \n",
    "$$\n",
    "\n",
    "where $ {\\bf x}_1 $ and $ {\\bf x}_2 $ are two subvectors of respective dimensions $ p $ and $ q $ with $ p+q=n $. Then, conditional distribution of $ {\\bf y} $ given $ {\\bf x} $ is also normal with mean vector\n",
    "\n",
    "$$\n",
    "\\mu_{\\bf y \\vert \\bf x} = \\mu_Y + C^TA^{-1}({\\bf x} - \\mu_X)\n",
    "$$\n",
    "\n",
    "and covariance matrix\n",
    "\n",
    "$$\n",
    "\\Sigma_{\\bf y \\vert \\bf x} = B - C^TA^{-1}C\n",
    "$$\n",
    "\n",
    "**Proof:**\n",
    "\n",
    "The joint density of $ {\\bf x} $ is:\n",
    "\n",
    "$$\n",
    "p({\\bf x},{\\bf y}) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}\\exp\\left[-\\frac{1}{2}Q(\\tilde{\\bf x})\\right]\n",
    "$$\n",
    "\n",
    "where $ Q $ is defined as\n",
    "\n",
    "$$\n",
    "Q(\\tilde{\\bf x}) = (\\tilde{\\bf x}-\\tilde{\\mu})^T\\Sigma^{-1}(\\tilde{\\bf x}-\\tilde{\\mu}) = [({\\bf x}-\\mu_X)^T, ({\\bf y}-\\mu_Y)^T] \\left[\\begin{array}{cc}\n",
    "A & C \\\\\n",
    "C^T&B\n",
    "\\end{array}\\right] \\left[\\begin{array}{c}\n",
    "{\\bf x}-\\mu_X \\\\\n",
    "{\\bf y}-\\mu_Y\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Here we have assumed\n",
    "\n",
    "$$\n",
    "\\Sigma^{-1} = \\left[\\begin{array}{cc}\n",
    "\\tilde{A} & \\tilde{C} \\\\\n",
    "\\tilde{C}^T&\\tilde{B}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\tilde{A} = (A-CB^{-1}C^T)^{-1}C^TA^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{B} = (B-C^TA^{-1}C)^{-1}CB^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{C} = -A^{-1}C(B-C^TA^{-1}C)^{-1} = \\tilde{C}^T\n",
    "$$\n",
    "\n",
    "Substituting into $ Q(\\tilde{\\bf x}) $ to get:\n",
    "\n",
    "$$\n",
    "Q(\\tilde{\\bf x}) = ({\\bf x}-\\mu_X)^T A^{-1} ({\\bf x}-\\mu_X) + [({\\bf y}-\\mu_Y)-C^TA^{-1}({\\bf x}-\\mu_X)]^T(B-C^TA^{-1}C)^{-1}[({\\bf y}-\\mu_Y)-C^TA^{-1}({\\bf x}-\\mu_X)]\n",
    "$$\n",
    "\n",
    "Now the joint distribution can be written as:\n",
    "\n",
    "$$\n",
    "p({\\bf x},{\\bf y}) = \\frac{1}{(2\\pi)^{n/2}|A|^{1/2}}\\exp\\left[-\\frac{1}{2}Q(\\tilde{\\bf x})\\right] = N({\\bf x}|\\mu_X,A) \\cdot N({\\bf y}|b,M)\n",
    "$$\n",
    "\n",
    "The conditional distribution of $ {\\bf y} $ given $ {\\bf x} $ is\n",
    "\n",
    "\\begin{align*}\n",
    "p({\\bf y}\\vert{\\bf x}) &= \\frac{p({\\bf x},{\\bf y})}{p({\\bf x})} \\\\\n",
    "&= \\frac{1}{(2\\pi)^{q/2}|M|^{1/2}}\\exp\\left[-\\frac{1}{2}({\\bf y}-b)^T M^{-1}({\\bf y}-b)\\right]\n",
    "\\end{align*}\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "b = \\mu_Y + C^TA^{-1}({\\bf x}-\\mu_X)\n",
    "$$\n",
    "\n",
    "$$\n",
    "M = B - C^TA^{-1}C\n",
    "$$\n",
    "\n",
    "Consider $n = 2$, then,\n",
    "\n",
    "$$\n",
    "b = \\mu_Y + \\frac{Cov(x,y)}{Var(x)}({x}-\\mu_X)\n",
    "$$\n",
    "\n",
    "$$\n",
    "M =  Var(y) - \\frac{Cov(x,y)^2}{Var(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bcc503",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_conditional_bivariate_normal_y_given_x(x_value, corr, varx):\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    mu = [0, 0]  # mean\n",
    "    sigma = [[varx, corr], [corr, 1]]  # covariance matrix\n",
    "    # Define grid points for y\n",
    "    y = np.linspace(-3.5, 3.5, 100)\n",
    "    \n",
    "    mu_y_given_x = mu[1] + sigma[1][0] / sigma[0][0] * (x_value - mu[0])\n",
    "    sigma_y_given_x = sigma[1][1] - sigma[1][0] / sigma[0][0] * sigma[0][1]\n",
    "    \n",
    "    \n",
    "    # Calculate the conditional bivariate normal PDF\n",
    "    conditional_pdf = multivariate_normal.pdf(y, mean=mu_y_given_x, cov=sigma_y_given_x)\n",
    "    \n",
    "    \n",
    "    # Plot conditional bivariate normal PDF\n",
    "    plt.plot(conditional_pdf, y)\n",
    "    plt.xlabel('Conditional Probability')\n",
    "    plt.title(f'Conditional Probability given X = {x_value}')\n",
    "\n",
    "def plot_bivariate_normal_with_line(x_value, corr, varx):\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    mu = [0, 0]  # mean\n",
    "    sigma = [[varx, corr], [corr, 1]]  # covariance matrix\n",
    "    def conditional_mean_function(x, positive_corr = True):\n",
    "        if positive_corr:\n",
    "            return mu[1] + sigma[1][0] / sigma[0][0] * (x - mu[0])\n",
    "        else:\n",
    "            return mu[1] - sigma[1][0] / sigma[0][0] * (x - mu[0])\n",
    "    # Generate grid points for x and y\n",
    "    x = np.linspace(-3.5, 3.5, 100)\n",
    "    y = np.linspace(-3.5, 3.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate the bivariate normal PDF for each pair of (x, y) values\n",
    "    pos = np.dstack((X, Y))\n",
    "    Z = multivariate_normal.pdf(pos, mean=mu, cov=sigma)\n",
    "    \n",
    "    # Plot bivariate normal PDF\n",
    "    plt.contour(X, Y, Z)\n",
    "    \n",
    "    # Plot vertical line for conditioning on X = x_value\n",
    "    plt.axvline(x=x_value, color='r', linestyle='--', label=f'X = {x_value}')\n",
    "    \n",
    "    # plot ellipsoid axis\n",
    "    positive_pos_axis = conditional_mean_function(x, positive_corr = True)\n",
    "    \n",
    "    plt.plot(x, positive_pos_axis, color=\"salmon\", linestyle=\"--\",label=\"$\\mu_{y/x}(x)$\")\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.title('Bivariate Normal Distribution')\n",
    "\n",
    "def conditioning_normal_distribution(x_value, corr, varx):\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Plot bivariate normal distribution with conditioning line\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_bivariate_normal_with_line(x_value, corr, varx)\n",
    "\n",
    "    # Plot conditional probability given X = x_value\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_conditional_bivariate_normal_y_given_x( x_value, corr, varx)\n",
    "\n",
    "#     plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529db770",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_1578448227333420800() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_1578448227333420800()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172634b7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23737954f28f40acb6853eafa502d62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='$X$:', layout=Layout(width='50%'), max=5.0, min=-5.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'handle_color': 'white', \"value\":\"white\"}\n",
    "widget = interact(conditioning_normal_distribution,\n",
    "         x_value=FloatSlider(value=0, min=-5, max=5, step=0.3, description='$X$:', layout=Layout(width='50%'), style= style),\n",
    "        corr=FloatSlider(value=0, min=-2, max=2, step=0.1, description='$Cov(x, y)$:', layout=Layout(width='50%'), style= style),\n",
    "        varx=FloatSlider(value=1, min=1e-3, max=5, step=0.1, description='$Var(x)$:', layout=Layout(width='50%'), style= style))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f96b08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Marginalisation\n",
    "\n",
    "<br>\n",
    "\n",
    "Given the two random vectors $\\mathbf{x}_{A}$ and $\\mathbf{x}_{B}$, the marginal probability of $\\mathbf{x}_{A}$ is given by,\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}_{A}) = \\int p(\\mathbf{x}_{A}, \\mathbf{x}_{B}) d\\mathbf{x}_{B}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea743098",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def plot_marginalized_distribution_x(mu, sigma):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    # Define grid points for x\n",
    "    x = np.linspace(-3.5, 3.5, 100)\n",
    "    \n",
    "    # Calculate the marginal distribution of X\n",
    "    marginal_pdf = []\n",
    "    for xi in x:\n",
    "        marginal_pdf.append(multivariate_normal.pdf(xi, mean=mu[0], cov=sigma[0][0]))\n",
    "    \n",
    "    # Plot marginalized distribution of X (rotated 90 degrees clockwise)\n",
    "    plt.plot(x, marginal_pdf)  # Interchange X and Y\n",
    "    \n",
    "    plt.title('Marginalized Distribution of X')\n",
    "\n",
    "def plot_marginalized_distribution_y(mu, sigma):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    # Define grid points for y\n",
    "    y = np.linspace(-3.5, 3.5, 100)\n",
    "    \n",
    "    # Calculate the marginal distribution of Y\n",
    "    marginal_pdf = []\n",
    "    for yi in y:\n",
    "        marginal_pdf.append(multivariate_normal.pdf(yi, mean=mu[1], cov=sigma[1][1]))\n",
    "    \n",
    "    # Plot marginalized distribution of Y (rotated 180 degrees clockwise and flipped)\n",
    "    plt.plot(marginal_pdf, y)  \n",
    "    \n",
    "    plt.title('Marginalized Distribution of Y')\n",
    "\n",
    "def plot_bivariate_normal_without_line(mu, sigma):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    # Generate grid points for x and y\n",
    "    x = np.linspace(-3.5, 3.5, 100)\n",
    "    y = np.linspace(-3.5, 3.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate the bivariate normal PDF for each pair of (x, y) values\n",
    "    pos = np.dstack((X, Y))\n",
    "    Z = multivariate_normal.pdf(pos, mean=mu, cov=sigma)\n",
    "    \n",
    "    # Plot bivariate normal PDF\n",
    "    plt.contour(X, Y, Z)\n",
    "    \n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Bivariate Normal Distribution')\n",
    "\n",
    "    \n",
    "def plot_marginalization_gaussian(mu1, mu2, sigma_x, sigma_y, cov):\n",
    "    mu = [mu1, mu2]  # mean\n",
    "    Sigma = [[sigma_x, cov], [cov, sigma_y]]  # covariance matrix\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 8), gridspec_kw={'width_ratios': [.75, .25], 'height_ratios': [.25, .75]})\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plot_marginalized_distribution_x(mu, Sigma)\n",
    "\n",
    "    axes[0, 1].remove()\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plot_bivariate_normal_without_line(mu, Sigma)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plot_marginalized_distribution_y(mu, Sigma)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e663d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: Gaussian Marginalisation\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Let $\\mathbf{x}$ and $\\mathbf{y}$ be jointly Gaussian random vector with dimension m and n, respectively.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{y}\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "\\mu_{X}\\\\\n",
    "\\mu_{Y}\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "show that $x \\sim \\mathcal{N}(\\mu_{X}, A)$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$\\textbf{Solution}:$\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = A \\begin{bmatrix}\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{y}\n",
    "\\end{bmatrix} = A \\bigg(\\begin{bmatrix}\n",
    "\\mu_{X}\\\\\n",
    "\\mu_{Y}\n",
    "\\end{bmatrix} + BZ\\bigg) = A \\begin{bmatrix}\n",
    "\\mu_{X}\\\\\n",
    "\\mu_{Y}\n",
    "\\end{bmatrix} + ABZ\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "A = [I_{m, m} , \\mathbf{0}_{m, n}]\n",
    "$$\n",
    "\n",
    "Therefore, $\\mathbf{x}$ is normally distributed with $\\mathbb{E}[\\mathbf{x}]=A \\begin{bmatrix}\n",
    "\\mu_{X}\\\\\n",
    "\\mu_{Y}\n",
    "\\end{bmatrix}=\\mu_{X}$ and $Cov(\\mathbf{x})=A \\begin{bmatrix}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{bmatrix} A^T=A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0f74709",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_13510459416031194749() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_13510459416031194749()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "466f4ca0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf591d1bb88b45bdb542ce918e4eaa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Mean1:', layout=Layout(width='50%'), max=5.0, min=-5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'handle_color': 'white', \"value\":\"white\"}\n",
    "widget = interact(plot_marginalization_gaussian,\n",
    "         mu1=FloatSlider(value=0, min=-5, max=5, step=1, description='Mean1:', layout=Layout(width='50%'), style= style),\n",
    "         mu2=FloatSlider(value=0, min=-5, max=5, step=1, description='Mean2:', layout=Layout(width='50%'), style= style),\n",
    "         sigma_x=FloatSlider(value=1, min=0.1, max=5, step=0.1, description='$\\sigma_{x}$:', layout=Layout(width='50%'), style= style),\n",
    "         sigma_y=FloatSlider(value=1, min=0.1, max=5, step=0.1, description='$\\sigma_{y}$:', layout=Layout(width='50%'), style= style),\n",
    "         cov=FloatSlider(value=0.5, min=-5, max=5, step=0.1, description='$\\sigma_{xy} = \\sigma_{yx}$::', layout=Layout(width='50%'), style= style))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd295675",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian Normal Samples\n",
    "\n",
    "Given a Cholesky decomposition of the covariance matrix to obtain the lower triangular matrix $L$,\n",
    "\n",
    "$$\n",
    "\\Sigma = L L^T\n",
    "$$\n",
    "\n",
    "Then, you can generate samples from a standard normal distribution and transform them using the mean vector and the Cholesky decomposition of the covariance matrix:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mu + L \\mathbf{z}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{z} \\sim N(\\mathbf{0}, I)$. For a single dimension we have,\n",
    "\n",
    "$$\n",
    "x = \\mu + \\sigma z\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f311fad",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_bivariate_gaussian_with_samples(num_samples, sigma_x, sigma_y, cov):\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    plot_2d_gaussian_density(0, 0, sigma_x, sigma_y, cov)\n",
    "    samples = plot_random_normal_samples(num_samples, sigma_x, sigma_y, cov)\n",
    "    plt.scatter(samples[:, 0], samples[:, 1])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_random_normal_samples(num_samples, sigma_x, sigma_y, cov):\n",
    "    mean = [0, 0]  # Mean of the distribution\n",
    "    np.random.seed(0)\n",
    "    covariance_matrix = np.array([[sigma_x, cov], [cov, sigma_y]])  # Covariance matrix\n",
    "    inverse_covariance_matrix = np.linalg.inv(covariance_matrix)  # Inverse of covariance matrix\n",
    "\n",
    "    # Generate samples\n",
    "    samples = np.random.randn(num_samples, 2)  # Generate samples from standard normal distribution\n",
    "\n",
    "    # Transform samples using the mean and covariance matrix\n",
    "    samples_transformed = mean + np.dot(samples, np.linalg.cholesky(covariance_matrix).T)\n",
    "    \n",
    "    # Print the generated samples\n",
    "    return samples_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b7334c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_12130023623761349867() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_12130023623761349867()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04180e48",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916004f09bc14caa96097afa7e3b1cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntText(value=3, description='$n$', layout=Layout(width='50%')), FloatSlider(value=3.0, …"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text input widgets for matrix values\n",
    "\n",
    "num_samples_text = widgets.IntText(value=3, description=r'$n$', layout=Layout(width='50%'))\n",
    "\n",
    "a11_text = FloatSlider(value=3, min=1e-3, max=5, step=0.5, description=r'$Var(x_1)$', layout=Layout(width='60%'), style= style)\n",
    "a22_text = FloatSlider(value=3, min=1e-3, max=5, step=0.5, description=r'$Var(x_2)$', layout=Layout(width='60%'), style= style)\n",
    "cov_text = FloatSlider(value=0, min=-4, max=4, step=0.5, description=r'$Cov(x_1, x_2)$', layout=Layout(width='60%'), style= style)\n",
    "\n",
    "# Use interact to link the text input widgets with the update_matrix function\n",
    "widgets.interactive(plot_bivariate_gaussian_with_samples, \n",
    "                    num_samples=num_samples_text,\n",
    "                    sigma_x= a11_text, \n",
    "                    sigma_y=a22_text, \n",
    "                    cov=cov_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f65229",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "\n",
    "Let $\\bf x$ and $\\bf y$ be jointly Gaussian random vectors,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\bf x \\\\\n",
    "\\bf y\n",
    "\\end{bmatrix} \\sim \\mathcal{N}\\left(\\mu = \\begin{bmatrix}\n",
    "\\mu_x \\\\\n",
    "\\mu_y\n",
    "\\end{bmatrix}, \\Sigma = \\begin{bmatrix}\n",
    "A & C \\\\\n",
    "C^T & B\n",
    "\\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "### Conditioning \n",
    "\n",
    "$$\n",
    "\\mathbf{ x} \\sim \\mathcal{N}(\\mu_x, A)\n",
    "$$\n",
    "\n",
    "### Marginalisation\n",
    "\n",
    "$$\n",
    "\\mathbf{ x}| \\mathbf{ y} \\sim \\mathcal{N}\\left(\\mu_x + CB^{-1}(\\mathbf{ y} - \\mu_y), A - CB^{-1}C^T\\right)\n",
    "$$\n",
    "\n",
    "### Sampling\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\bf x \\\\\n",
    "\\bf y\n",
    "\\end{bmatrix}  = \\mu + L \\mathbf{z} \\text{, where } \\Sigma = L L^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58347b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Process\n",
    "\n",
    "It is a collection of random variables, where any finite number of variables have a joint Gaussian distribution. A Gaussian process (GP) is defined by its mean function $m(x)$ and covariance function $k(x, x')$ as,\n",
    "\n",
    "$$\n",
    "f(x) \\sim GP(m(x), k(x, x'))\n",
    "$$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Mean Function**: $m(x) = \\mathbb{E}[f(x)]$\n",
    "<br>\n",
    "<br>\n",
    "- **Covariance Function**: $k(x, x') = \\mathbb{E}[(f(x) - m(x))(f(x) - m(x'))]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ad654ab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define mean function and covariance function of the Gaussian process\n",
    "def mean_function_on_x(x):\n",
    "    return np.sin(x) + 0.1 * x + 0.01 * x**2\n",
    "\n",
    "def covariance_function_on_x(x1, x2, length_scale=1.0, amplitude=1.0):\n",
    "    return amplitude(x1) * np.exp(-0.5 * (np.subtract.outer(x1, x2) / length_scale)**2) * amplitude(x2)\n",
    "\n",
    "# Define spatially-varying amplitude function for variance\n",
    "def amplitude_function(x):\n",
    "    return 0.1 + 0.05 * np.sin(x)\n",
    "\n",
    "\n",
    "def marginal_Gaussian_process_value_evaluated_on_x(mean, covariance, x, x_value):\n",
    "    # Calculate the mean and variance of the normal distribution at the given location x_value\n",
    "    x_index = np.abs(x - x_value).argmin()  # Index of x_value in x\n",
    "    normal_mean = mean[x_index]\n",
    "    normal_variance = covariance[x_index, x_index]\n",
    "    \n",
    "    x_values = np.linspace(normal_mean - 3 * np.sqrt(normal_variance), normal_mean + 3 * np.sqrt(normal_variance), 100)\n",
    "\n",
    "    # Calculate the corresponding y values using the normal distribution\n",
    "    y_values = norm.pdf(x_values, loc=normal_mean, scale=np.sqrt(normal_variance))\n",
    "\n",
    "    plt.plot( y_values, x_values,color='blue')\n",
    "\n",
    "    # Customize plot\n",
    "    plt.title('Normal Distribution at x = {:.2f}'.format(x_value))\n",
    "    plt.ylim((-0.55, 3.01))\n",
    "    \n",
    "# Define the locations where we want to evaluate the Gaussian process\n",
    "def plot_gaussian_process_evaluated_on_x(x_value):\n",
    "    x = np.linspace(0, 10, 100)  # Define locations\n",
    "\n",
    "    # Compute mean and covariance matrices for the given locations\n",
    "    mean = mean_function_on_x(x)\n",
    "    covariance = covariance_function_on_x(x, x, amplitude=amplitude_function)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), gridspec_kw={'width_ratios': [.75, .25]})\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    # Plot mean function\n",
    "    plt.plot(x, mean, color='black', label='Mean')\n",
    "    plt.fill_between(x, mean - 3 * np.sqrt(np.diag(covariance)), mean + 3 * np.sqrt(np.diag(covariance)), color='blue', alpha=0.2, label='Uncertainty')\n",
    "    plt.title('Gaussian Process with Mean Prediction and Uncertainty')\n",
    "    plt.axvline(x=x_value, color='r', linestyle='--', label=f'X = {x_value}')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('f(X)')\n",
    "    plt.xlim((0,10))\n",
    "    plt.ylim((-0.55, 3.01))\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot conditional probability given X = x_value\n",
    "    plt.subplot(1, 2, 2)\n",
    "    marginal_Gaussian_process_value_evaluated_on_x(mean, covariance, x, x_value)\n",
    "\n",
    "    # Customize plot\n",
    "\n",
    "    plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b25989",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_7038180819717060080() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_7038180819717060080()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88d4a48a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e4e984e78c4d30975ed864dc63a140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='X:', layout=Layout(width='50%'), max=10.0, step=0.3,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'handle_color': 'white', \"value\":\"white\"}\n",
    "widget = interact(plot_gaussian_process_evaluated_on_x,\n",
    "         x_value=FloatSlider(value=0, min=0, max=10, step=0.3, description='X:', layout=Layout(width='50%'), style= style))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a4796",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mean Function\n",
    "\n",
    "<br>\n",
    "\n",
    "The mean function represents the expected value of the process at any given point. \n",
    "\n",
    "- **Zero Mean Function**: The simplest assumption is to assume that it is zero everywhere, i.e., $ m(x) = 0 $ for all $ x $. \n",
    "\n",
    "<br>\n",
    "\n",
    "- **Non-Zero Mean Function**: In some cases, prior knowledge or domain expertise may suggest a non-zero mean function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c2ab4bd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import kv\n",
    "from scipy.special import gamma\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Math\n",
    "\n",
    "def mean_sin(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "def mean_linear(x):\n",
    "    return x*(1/4)\n",
    "\n",
    "\n",
    "def mean_zero(x):\n",
    "    return np.zeros_like(x)\n",
    "\n",
    "\n",
    "class kernel_matern:\n",
    "    def __init__(self, length_scale=1.0, nu=0.5, amplitude=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.nu = nu\n",
    "        self.amplitude = amplitude\n",
    "    \n",
    "    def print_formula(self):\n",
    "        eqn = r\"k_{\\text{Matern}}(x, x') = \\sigma^2\\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left(\\frac{\\sqrt{2\\nu}}{l} | x - x' | \\right)^\\nu K_\\nu \\left(\\frac{\\sqrt{2\\nu}}{l} | x - x' | \\right)\"\n",
    "        display(Math(r\"\\text{Matérn Kernel:}\"))\n",
    "        display(Math(eqn))\n",
    "    \n",
    "    def compute(self, x1, x2):\n",
    "        dist = np.sqrt((x1[:, None] - x2[None, :])**2)\n",
    "        dist[dist == 0.0] += np.finfo(float).eps\n",
    "        term1 = 2**(1 - self.nu) / gamma(self.nu)\n",
    "        term2 = np.sqrt(2 * self.nu) * dist / self.length_scale\n",
    "        term3 = kv(self.nu, term2)\n",
    "        return self.amplitude * term1 * (term2 ** self.nu) * term3\n",
    "    \n",
    "    def update_ls(self, ls):\n",
    "        self.length_scale = ls\n",
    "    \n",
    "    def update_nu(self, nu):\n",
    "        self.nu = nu\n",
    "    \n",
    "    def update_amplitude(self, amp):\n",
    "        self.amplitude = amp\n",
    "\n",
    "        \n",
    "class kernel_gaussian():\n",
    "    def __init__(self,length_scale=1.0, amplitude=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.amplitude = amplitude\n",
    "    \n",
    "    def print_formula(self):\n",
    "        eqn = r\"\"\"\n",
    "k_{\\text{RBF}}(x, x') = \\exp\\left(-\\frac{(x - x')^2}{2l^2}\\right)\n",
    "\"\"\"\n",
    "        display(Math(r\"\\text{RBF Kernel:}\"))\n",
    "        display(Math(eqn))\n",
    "        \n",
    "    def compute(self, x1, x2):\n",
    "         return self.amplitude * np.exp(-0.5 * ((x1[:, None] - x2[None, :]) / self.length_scale)**2)\n",
    "    \n",
    "    def update_ls(self,ls):\n",
    "        self.length_scale = ls\n",
    "    \n",
    "    def update_amplitude(self,amp):\n",
    "        self.amplitude = amp\n",
    "        \n",
    "class kernel_linear():\n",
    "    def __init__(self,intersect= 1.0, slope=1/4):\n",
    "        self.slope = slope\n",
    "        self.intersect = intersect\n",
    "    \n",
    "    def print_formula(self):\n",
    "        eqn = r\"\"\"\n",
    "k_{\\text{Linear}}(x, x') = (x - c) (x' - c)\\sigma^2_v + \\sigma^2_b\n",
    "\"\"\"\n",
    "        display(Math(r\"\\text{Periodic Kernel:}\"))\n",
    "        display(Math(eqn))\n",
    "            \n",
    "    def compute(self, x1, x2):\n",
    "         return self.intersect + self.slope * (x1[:, None] ) *(x2[None, :] )\n",
    "    \n",
    "    def update_slope(self,slope):\n",
    "        self.slope = slope\n",
    "    \n",
    "    def update_intersect(self,intersect):\n",
    "        self.intersect = intersect\n",
    "        \n",
    "class kernel_periodic():\n",
    "    def __init__(self,length_scale=1.0, period=1.0, amplitude=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.period = period\n",
    "        self.amplitude = amplitude\n",
    "    \n",
    "    def print_formula(self):\n",
    "        eqn = r\"\"\"\n",
    "k_{\\text{Periodic}}(x, x') = \\sigma^2\\exp\\left(-\\frac{2\\sin^2(\\pi | x - x' | / p)}{\\ell^2}\\right)\n",
    "\"\"\"\n",
    "        display(Math(r\"\\text{Periodic Kernel:}\"))\n",
    "        display(Math(eqn))\n",
    "        \n",
    "    def compute(self, x1, x2):\n",
    "         return self.amplitude * np.exp(-2 * (np.sin(np.pi * np.abs(x1[:, None] - x2[None, :]) / self.period) / self.length_scale)**2)\n",
    "    \n",
    "    def update_ls(self,ls):\n",
    "        self.length_scale = ls\n",
    "    \n",
    "    def update_amplitude(self,amp):\n",
    "        self.amplitude = amp\n",
    "    \n",
    "    def update_period(self,period):\n",
    "        self.period = period\n",
    "        \n",
    "class kernel_white_noise():\n",
    "    def __init__(self,noise=1.0):\n",
    "        self.noise =noise\n",
    "    \n",
    "    def print_formula(self):\n",
    "        eqn = r\"\"\"\n",
    "k_{\\text{WhiteNoise}}(x, x') = \\sigma^2 \\delta(x, x')\n",
    "\"\"\"\n",
    "        display(Math(r\"\\text{White Noise Kernel:}\"))\n",
    "        display(Math(eqn))\n",
    "\n",
    "    def compute(self, x1, x2):\n",
    "        return np.identity(len(x1)) * self.noise\n",
    "    \n",
    "    def update_noise(self, noise):\n",
    "        self.noise = noise\n",
    "\n",
    "def plot_gaussian_process(mean_function, covariance_function, num_samples=5):\n",
    "    # Define the locations where we want to evaluate the Gaussian process\n",
    "    x = np.linspace(0, 10, 80)  # Define locations\n",
    "\n",
    "    # Compute mean and covariance matrices for the given locations\n",
    "    mean = mean_function(x)\n",
    "    covariance = covariance_function(x, x)\n",
    "    # Sample from the Gaussian process distribution\n",
    "    samples = np.random.multivariate_normal(mean, covariance, size=num_samples)\n",
    "\n",
    "#     # Plotting\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot mean function\n",
    "    plt.plot(x, mean, color='black', linestyle='--', label='Mean')\n",
    "\n",
    "    # Plot uncertainty (two standard deviations above and below the mean)\n",
    "    plt.fill_between(x, mean - 2 * np.sqrt(np.diag(covariance)), mean + 2 * np.sqrt(np.diag(covariance)), color='blue', alpha=0.2, label='Uncertainty')\n",
    "\n",
    "    # Plot realizations\n",
    "    for i in range(num_samples):\n",
    "        plt.plot(x, samples[i], label=f'Realization {i+1}')\n",
    "\n",
    "    # Customize plot\n",
    "    plt.title('Gaussian Process with Mean Prediction and Uncertainty')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlim((0,10))\n",
    "    plt.ylim((-4,4))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "def plot_covariance_matrix(covariance_function):\n",
    "    x = np.linspace(0, 10, 80)  # Define locations\n",
    "    covariance = covariance_function(x, x)\n",
    "    sn.heatmap(covariance, cmap=\"coolwarm\", xticklabels=False, yticklabels=False)\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(\"Kernel Matrix\")\n",
    "    plt.xlabel(r\"$x$\", size=16)\n",
    "    plt.ylabel(r\"$x'$\", size=16)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c63f8e9e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_16844395146537895026() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_16844395146537895026()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d4262bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c3dc6ca4f042e39a293bc4b3d632bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Sin Mean Function', style=ButtonStyle()), Button(description='Linear Mean F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an output widget\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create buttons for mean functions\n",
    "button_sin = widgets.Button(description='Sin Mean Function')\n",
    "button_linear = widgets.Button(description='Linear Mean Function')\n",
    "\n",
    "# Define callback functions for buttons\n",
    "def on_click_sin(b):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        covariance_function = kernel_gaussian()\n",
    "        plot_gaussian_process(mean_sin, covariance_function.compute)\n",
    "        plt.show()\n",
    "def on_click_linear(b):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        covariance_function = kernel_gaussian()\n",
    "        plot_gaussian_process(mean_linear, covariance_function.compute)\n",
    "        plt.show()\n",
    "# Assign callback functions to buttons\n",
    "button_sin.on_click(on_click_sin)\n",
    "button_linear.on_click(on_click_linear)\n",
    "\n",
    "# Display buttons and output widget\n",
    "display(widgets.VBox([button_sin, button_linear, output]))\n",
    "\n",
    "# Trigger the default output\n",
    "on_click_sin(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c014a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Covariance Function\n",
    "\n",
    "$\\textbf{Define}$:\n",
    "- Similarity/correlation between data points\n",
    "- Smoothness\n",
    "- Periodicity\n",
    "\n",
    "$\\textbf{Properties}$:\n",
    " - Symmetric\n",
    " - Positive Semi-definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88e19172",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9848595886116565966() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9848595886116565966()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7f2d479",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc18ef83a3f4b63a3f5ab10adba1399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Button(description='Matern Kernel', style=ButtonStyle()), Button(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create buttons for mean and kernel functions\n",
    "button_kernel_gaussian = widgets.Button(description='Gaussian Kernel')\n",
    "button_kernel_gaussian.style.text_color = \"black\"\n",
    "button_kernel_linear = widgets.Button(description='Linear Kernel')\n",
    "button_kernel_periodic = widgets.Button(description='Periodic Kernel')\n",
    "button_kernel_white_noise = widgets.Button(description='White Noise Kernel')\n",
    "button_kernel_matern = widgets.Button(description='Matern Kernel')\n",
    "# Create an output widget\n",
    "output2 = widgets.Output()\n",
    "\n",
    "kernel_gaussian_instance = kernel_gaussian()\n",
    "kernel_linear_instance = kernel_linear()\n",
    "kernel_periodic_instance = kernel_periodic()\n",
    "kernel_white_noise_instance = kernel_white_noise()\n",
    "kernel_matern_instance = kernel_matern()\n",
    "# Define callback functions for buttons\n",
    "\n",
    "def on_click_kernel_matern(b):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_matern_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_matern_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix( kernel_matern_instance.compute)\n",
    "        plt.show()\n",
    "def on_click_kernel_gaussian(b):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_gaussian_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_gaussian_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix( kernel_gaussian_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def on_click_kernel_linear(b):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_linear_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_linear_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix( kernel_linear_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def on_click_kernel_periodic(b):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_periodic_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_periodic_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix( kernel_periodic_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def on_click_kernel_white_noise(b):\n",
    "    with output2:\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_white_noise_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_white_noise_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_white_noise_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def matern_lengtscale_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_matern_instance.print_formula()\n",
    "        kernel_matern_instance.update_ls(hyper)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_matern_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_matern_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def matern_amplitude_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_matern_instance.print_formula()\n",
    "        kernel_matern_instance.update_amplitude(hyper)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_matern_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_matern_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def matern_nu_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_matern_instance.print_formula()\n",
    "        kernel_matern_instance.update_nu(hyper)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_matern_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_matern_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def rbf_lengtscale_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_gaussian_instance.update_ls(hyper)\n",
    "        kernel_gaussian_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_gaussian_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_gaussian_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def rbf_amplitude_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_gaussian_instance.update_amplitude(hyper)\n",
    "        kernel_gaussian_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_gaussian_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_gaussian_instance.compute)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "def linear_slope_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_linear_instance.update_slope(hyper)\n",
    "        kernel_linear_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_linear_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_linear_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "def linear_intersect_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_linear_instance.update_intersect(hyper)\n",
    "        kernel_linear_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_linear_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_linear_instance.compute)\n",
    "        plt.show()\n",
    "\n",
    "def periodic_amplitude_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_periodic_instance.update_amplitude(hyper)\n",
    "        kernel_periodic_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_periodic_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_periodic_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def periodic_period_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_periodic_instance.update_period(hyper)\n",
    "        kernel_periodic_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_periodic_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_periodic_instance.compute)\n",
    "        plt.show()\n",
    "\n",
    "def periodic_ls_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_periodic_instance.update_ls(hyper)\n",
    "        kernel_periodic_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_periodic_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_periodic_instance.compute)\n",
    "        plt.show()\n",
    "\n",
    "def white_noise_noise_changed(hyper):\n",
    "    with output2:\n",
    "        np.random.seed(0)\n",
    "        output2.clear_output(wait=True)\n",
    "        kernel_white_noise_instance.update_noise(hyper)\n",
    "        kernel_white_noise_instance.print_formula()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel_white_noise_instance.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel_white_noise_instance.compute)\n",
    "        plt.show()\n",
    "        \n",
    "# Assign callback functions to buttons\n",
    "button_kernel_gaussian.on_click(on_click_kernel_gaussian)\n",
    "rbf_lengtscale = widgets.FloatText(value=1, description=r'$l$', layout=Layout(width='50%'))\n",
    "rbf_lengtscale.observe(lambda event, index: rbf_lengtscale_changed(event['new']), names='value')\n",
    "rbf_amplitude = widgets.FloatText(value=1, description=r'$\\sigma^2$', layout=Layout(width='50%'))\n",
    "rbf_amplitude.observe(lambda event, index: rbf_amplitude_changed(event['new']), names='value')\n",
    "\n",
    "button_kernel_linear.on_click(on_click_kernel_linear)\n",
    "linear_slope = widgets.FloatText(value=1/4, description=r'$\\sigma^2_v$', layout=Layout(width='50%'))\n",
    "linear_slope.observe(lambda event, index: linear_slope_changed(event['new']), names='value')\n",
    "linear_intersect = widgets.FloatText(value=1, description=r'$\\sigma^2_b$', layout=Layout(width='50%'))\n",
    "linear_intersect.observe(lambda event, index: linear_intersect_changed(event['new']), names='value')\n",
    "\n",
    "button_kernel_periodic.on_click(on_click_kernel_periodic)\n",
    "periodic_amplitude =  widgets.FloatText(value=1, description=r'$\\sigma^2$', layout=Layout(width='50%'))\n",
    "periodic_amplitude.observe(lambda event, index: periodic_amplitude_changed(event['new']), names='value')\n",
    "periodic_lengtscale = widgets.FloatText(value=1, description=r'$l$', layout=Layout(width='50%'))\n",
    "periodic_lengtscale.observe(lambda event, index: periodic_ls_changed(event['new']), names='value')\n",
    "periodic_period = widgets.FloatText(value=1, description=r'$p$', layout=Layout(width='50%'))\n",
    "periodic_period.observe(lambda event, index: periodic_period_changed(event['new']), names='value')\n",
    "\n",
    "button_kernel_white_noise.on_click(on_click_kernel_white_noise)\n",
    "white_noise_noise =  widgets.FloatText(value=1, description=r'$\\sigma^2$', layout=Layout(width='50%'))\n",
    "white_noise_noise.observe(lambda event, index: white_noise_noise_changed(event['new']), names='value')\n",
    "\n",
    "\n",
    "button_kernel_matern.on_click(on_click_kernel_matern)\n",
    "matern_lengtscale = widgets.FloatText(value=1, description=r'$l$', layout=Layout(width='50%'))\n",
    "matern_lengtscale.observe(lambda event, index: matern_lengtscale_changed(event['new']), names='value')\n",
    "matern_amplitude = widgets.FloatText(value=1, description=r'$\\sigma^2$', layout=Layout(width='50%'))\n",
    "matern_amplitude.observe(lambda event, index: matern_amplitude_changed(event['new']), names='value')\n",
    "options = [1/2, 3/2, 5/2]\n",
    "matern_nu = widgets.Dropdown(options=options, description=r'$\\nu$', value=options[0], layout=Layout(width='60%'))\n",
    "matern_nu.observe(lambda event, index: matern_nu_changed(event['new']), names='value')\n",
    "\n",
    "# Display buttons and output widget\n",
    "# display(widgets.VBox([button_kernel_gaussian, button_kernel_linear, button_kernel_periodic, button_kernel_white_noise, output2]))\n",
    "widget1 =widgets.VBox([button_kernel_matern, button_kernel_periodic, button_kernel_gaussian, button_kernel_linear, button_kernel_white_noise])\n",
    "widget2 =widgets.VBox([matern_lengtscale,  periodic_lengtscale, rbf_lengtscale, linear_slope, white_noise_noise])\n",
    "widget3 =widgets.VBox([matern_amplitude, periodic_amplitude, rbf_amplitude, linear_intersect])\n",
    "widget4 =widgets.VBox([matern_nu, periodic_period])\n",
    "interactive_buttons = widgets.HBox([widget1, widget2, widget3, widget4])\n",
    "\n",
    "display(widgets.VBox([interactive_buttons, output2]))\n",
    "on_click_kernel_matern(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ee0e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining Kernels\n",
    "\n",
    "\n",
    "- $\\bf Summing\\text{ } Kernels$: The resulting covariance allows to capture various patterns simultaneously.\n",
    "\n",
    "$$\n",
    "k_{\\text{sum}}(x, x') = k_1(x, x') + k_2(x, x') + \\dots + k_n(x, x')\n",
    "$$\n",
    "\n",
    "\n",
    "- $\\bf Multiplying \\text{ }Kernels$: This approach is useful for modeling interactions between different patterns present in the data. \n",
    "\n",
    "\n",
    "$$\n",
    "k_{\\text{mult}}(x, x') = k_1(x, x') \\times k_2(x, x') \\times \\dots \\times k_n(x, x')\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09855399",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_6776565157770082116() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_6776565157770082116()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ebc4634",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfdca2368a34a5ea961a88f9d94d6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Dropdown(description='Operation', layout=Layout(width='60%'), options=('addition…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_operation = widgets.Output()\n",
    "\n",
    "class addition_kernel():\n",
    "    def __init__(self, kernel1, kernel2):\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "    \n",
    "    def compute(self,x1, x2):\n",
    "        return self.kernel1.compute(x1, x2) + self.kernel2.compute(x1, x2)\n",
    "\n",
    "    \n",
    "class multiplication_kernel():\n",
    "    def __init__(self, kernel1, kernel2):\n",
    "        self.kernel1 = kernel1\n",
    "        self.kernel2 = kernel2\n",
    "    \n",
    "    def compute(self,x1, x2):\n",
    "        return self.kernel1.compute(x1, x2) * self.kernel2.compute(x1, x2)\n",
    "    \n",
    "def kernel_operation_changed(operation):\n",
    "    with output_operation:\n",
    "        np.random.seed(0)\n",
    "        output_operation.clear_output(wait=True)\n",
    "        if operation == \"addition\":\n",
    "            kernel = addition_kernel(kernel_linear(), kernel_periodic())\n",
    "        else:\n",
    "            kernel = multiplication_kernel(kernel_linear(), kernel_periodic())\n",
    "        display(Math(r\"Operation(k_{Linear}, k_{Periodic})\"))\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plot_gaussian_process(mean_zero, kernel.compute)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plot_covariance_matrix(kernel.compute)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "options = [\"addition\", \"multiplication\"]\n",
    "operation_widget = widgets.Dropdown(options=options, description=r'Operation', value=options[0], layout=Layout(width='60%'))\n",
    "operation_widget.observe(lambda event, index: kernel_operation_changed(event['new']), names='value')\n",
    "widget_operation =widgets.VBox([operation_widget, output_operation])\n",
    "display(widgets.VBox([widget_operation]))\n",
    "kernel_operation_changed(\"addition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb223c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Distribution\n",
    "\n",
    "Given the noise-free observations $ \\mathbf{f} $, the joint distribution of observed data and the function values at the test point $ X^* $ can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{f} \\\\\n",
    "\\mathbf{f}^*\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "\\textbf{m}\\\\\n",
    "\\mathbf{m}^*\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "K(X,X) & K(X, X^*) \\\\\n",
    "K(X^*, X) & K(X^*, X^*) \n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "The predictive distribution is obtained by conditioning on the observed data:\n",
    "\n",
    "$$\n",
    "\\mathbf{f}^* | \\mathbf{f} \\sim \\mathcal{N}(\\mu^*, \\Sigma^*)\n",
    "$$\n",
    "\n",
    "$$ \\mu^* = \\textbf{m}^* + K(X^*, X)^T K(X,X)^{-1} (\\mathbf{f} - \\mathbf{m}) $$\n",
    "\n",
    "$$ \\Sigma^* = K(X^*,X^*) - K(X^*, X)^T K(X,X)^{-1} K(X, X^*) $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c56fe4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Distribution using Noisy Observation\n",
    "\n",
    "\n",
    "Consider, $\n",
    "y = f(x) + \\epsilon,\\text{ where }\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\nu}^2)$\n",
    "\n",
    "Therefore, the joint distribution is,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{y} \\\\\n",
    "\\mathbf{f}^*\n",
    "\\end{bmatrix}\n",
    "\\sim\n",
    "\\mathcal{N}\\left(\n",
    "\\begin{bmatrix}\n",
    "\\textbf{m}\\\\\n",
    "\\mathbf{m}^*\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "K(X,X) +  \\sigma_{\\nu}^2 & K(X, X^*) \\\\\n",
    "K(X^*, X) & K(X^*, X^*) \n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "and,\n",
    "\n",
    "$$\n",
    "\\mathbf{f}^* | \\mathbf{y} \\sim \\mathcal{N}(\\mu^*, \\Sigma^*)\n",
    "$$\n",
    "$$\n",
    "\\mu^* = \\textbf{m}^* + K(X^*, X)^T [K(X,X) + \\sigma_{\\nu}^2 I]^{-1} (\\mathbf{y} - \\mathbf{m}) \n",
    "$$\n",
    "$$\n",
    "\\Sigma^* = K(X^*,X^*) - K(X^*, X)^T [K(X,X) + \\sigma_{\\nu}^2 I]^{-1}  K(X, X^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84eb32a7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianProcessRegressor:\n",
    "    def __init__(self, kernel, sigma_noise=1e-6):\n",
    "        self.kernel = kernel\n",
    "        self.sigma_noise = sigma_noise\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.K = self.kernel(self.X_train, self.X_train)\n",
    "        self.K += np.eye(len(self.X_train)) * self.sigma_noise  # Adding noise to the diagonal for numerical stability\n",
    "        self.K_inv = np.linalg.inv(self.K)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        K_s = self.kernel(self.X_train, X_test)\n",
    "        mu_s = K_s.T.dot(self.K_inv).dot(self.y_train)\n",
    "        cov_s = self.kernel(X_test, X_test) - K_s.T.dot(self.K_inv).dot(K_s)\n",
    "        return mu_s.reshape(-1), np.sqrt(np.diag(cov_s))\n",
    "\n",
    "def underlying_function(x):\n",
    "    return np.sin(x) + np.sin((10.0 / 3.0) * x)\n",
    "\n",
    "\n",
    "def plot_gaussian_process_with_changing_hypers(x_value, ls, sigma, noise_variance):\n",
    "    \n",
    "    # Define a simple RBF kernel\n",
    "    def rbf_kernel(X1, X2, length_scale=ls, sigma_f=sigma):\n",
    "        sq_dist = np.sum(X1**2, axis=1).reshape(-1, 1) + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
    "        return sigma_f**2 * np.exp(-0.5 / length_scale**2 * sq_dist)\n",
    "\n",
    "    X_train_existing = np.array([-2, -1, 1, 2]).reshape(-1, 1)\n",
    "\n",
    "    new_x_value = np.array([[x_value]])\n",
    "\n",
    "    # Concatenate the new x_value with the existing X_train array\n",
    "    X_train = np.concatenate([X_train_existing, new_x_value], axis=0)\n",
    "    # Define some training data\n",
    "    \n",
    "    y_train = underlying_function(X_train)\n",
    "\n",
    "    # Define test data\n",
    "    X_test_base = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "    X_test = np.sort(np.concatenate([X_test_base, new_x_value], axis=0), axis=0)\n",
    "    Y_true_f = underlying_function(X_test)\n",
    "    # Create Gaussian Process Regressor\n",
    "    gp = GaussianProcessRegressor(kernel=rbf_kernel, sigma_noise=noise_variance)\n",
    "\n",
    "    # Fit the model\n",
    "    gp.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_mean, y_pred_std = gp.predict(X_test)\n",
    "\n",
    "    data = np.concatenate([X_train, y_train], axis=1)\n",
    "    df_train = pd.DataFrame(data, columns=['X', 'Y'])\n",
    "\n",
    "    data = np.concatenate([X_test, y_pred_mean.reshape(-1, 1), (y_pred_mean - y_pred_std).reshape(-1, 1), (y_pred_mean + y_pred_std).reshape(-1, 1)], axis=1)\n",
    "    df_pred = pd.DataFrame(data, columns=['X', 'Predicted Mean', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Plot the results using Seaborn\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sn.scatterplot(x='X', y='Y', data=df_train, color='black', label='Training Data')\n",
    "    sn.lineplot(x='X', y='Predicted Mean', data=df_pred, color='blue', label='Predicted Mean')\n",
    "    plt.fill_between(df_pred['X'], df_pred['Lower Bound'], df_pred['Upper Bound'], color='black', alpha=0.2, label='Uncertainty')\n",
    "    plt.axvline(x=x_value, color='r', linestyle='--', label=f'X = {x_value}')\n",
    "    plt.plot(X_test, Y_true_f)\n",
    "    plt.xlim((-3, 3))\n",
    "    plt.ylim((-2,2))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Gaussian Process Regression')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79f31948",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_9030624161115580034() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_9030624161115580034()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db2a72a4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e42770efa0d4877aaf480f2204f6dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='$x_{new}$:', layout=Layout(width='50%'), max=3.0, mi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'handle_color': 'white', \"value\":\"white\"}\n",
    "widget = interact(plot_gaussian_process_with_changing_hypers,\n",
    "         x_value=FloatSlider(value=0, min=-3, max=3, step=0.001, description='$x_{new}$:', layout=Layout(width='50%'), style= style),\n",
    "         ls=FloatSlider(value=1, min=1e-3, max=3, step=0.1, description='$l$:', layout=Layout(width='50%'), style= style),\n",
    "        sigma=FloatSlider(value=1, min=1e-3, max=20, step=0.1, description='$\\sigma_k$:', layout=Layout(width='50%'), style= style),\n",
    "        noise_variance=FloatSlider(value=1e-6, min=1e-6, max=2, step=0.01, description='$\\sigma^2_{\\nu}$:', layout=Layout(width='50%'), style= style))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b5d21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Hyperparameters\n",
    "\n",
    "Given the marginal likelihood of the observed data.\n",
    "\n",
    "$$\n",
    "p(\\mathbf{f}^* | X, \\mathbf{y}, X^*, \\theta) = \\frac{p(\\mathbf{y} , \\mathbf{f}^*| X^*, X, \\theta)}{\\underbrace{p(\\mathbf{y} | \\mathbf{X}, \\theta)}_{\\text{marginal likelihood}}} = \\frac{p(\\mathbf{y} , \\mathbf{f}^*| X^*, X, \\theta)}{ \\int p(\\mathbf{y} | \\mathbf{f}) p(\\mathbf{f} | X, \\theta) d\\mathbf{f} }\n",
    "$$\n",
    "\n",
    "We maximize the marginal likelihood with respect to the hyperparameters $\\theta$. \n",
    "\n",
    "$$\n",
    "\\theta^* = \\text{argmax}_\\theta \\left( -\\log p(\\mathbf{y} | X, \\theta) \\right)\n",
    "$$\n",
    "\n",
    "where, $\\log p(y | X, \\theta) = -\\frac{1}{2} \\left( \\mathbf{y}^\\top (K(X, X) + \\sigma_n^2 I)^{-1} \\mathbf{y} + \\log |K(X,X) + \\sigma_n^2 I| + n \\log (2\\pi) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0ed53c2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Define a simple RBF kernel\n",
    "def kernel(length_scale, sigma_f):\n",
    "    def rbf_kernel(X1, X2):\n",
    "        sq_dist = np.sum(X1**2, axis=1).reshape(-1, 1) + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
    "        return sigma_f**2 * np.exp(-(0.5 / length_scale**2) * sq_dist)\n",
    "    return rbf_kernel\n",
    "\n",
    "def marginal_likelihood(X, y):\n",
    "    def compute_log_marginal_likelihood(length_scale, noise_level):\n",
    "        rbf_kernel = kernel(length_scale, sigma_f=1)\n",
    "        K = rbf_kernel(X, X) + noise_level**2 * np.eye(len(X))\n",
    "        # Cholesky decomposition of the covariance matrix\n",
    "        L = np.linalg.cholesky(K + 1e-6 * np.eye(len(X)))\n",
    "        # Solve for alpha: K * alpha = y\n",
    "        alpha = np.linalg.solve(L.T, np.linalg.solve(L, y))\n",
    "        # Compute log determinant of the covariance matrix\n",
    "        log_det_K = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "        # Compute log marginal likelihood\n",
    "        log_marginal_likelihood = -0.5 * ((y.T).dot(alpha) + log_det_K + len(X) * np.log(2 * np.pi))\n",
    "        return log_marginal_likelihood\n",
    "    return compute_log_marginal_likelihood\n",
    "\n",
    "def plot_marginal_likelihood_at_location(length_scale, noise_level):\n",
    "    np.random.seed(19)\n",
    "    lb = -2.5\n",
    "    ub = 2.5\n",
    "    X = (np.random.random(4)*(ub - lb) + lb).reshape(-1, 1)\n",
    "    y = underlying_function(X) + np.random.random(len(X)).reshape(-1,1)*0.3\n",
    "    log_marginal_likelihood = marginal_likelihood(X, y)\n",
    "\n",
    "    # Define the range of hyperparameters\n",
    "    noise_levels = np.linspace(1e-6, 1.0, 60)\n",
    "    length_scales = np.linspace(0.1, 1.0, 20)\n",
    "\n",
    "    # Create a grid of hyperparameter values\n",
    "    noise_levels_grid, length_scales_grid = np.meshgrid(noise_levels, length_scales)\n",
    "\n",
    "    # Compute the log marginal likelihood for each combination of hyperparameters\n",
    "    log_likelihood_values = np.zeros_like(noise_levels_grid)\n",
    "    for i in range(len(length_scales)):\n",
    "        for j in range(len(noise_levels)):\n",
    "            log_likelihood_values[i, j] = np.exp(log_marginal_likelihood(length_scales[i], noise_levels[j]))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    sn.set_style(\"darkgrid\")\n",
    "    # Plot the landscape of the log marginal likelihood\n",
    "    plt.contourf(noise_levels_grid, length_scales_grid, log_likelihood_values, levels=50)\n",
    "    plt.contour(noise_levels_grid, length_scales_grid, log_likelihood_values, levels=50, colors='black')\n",
    "    plt.scatter(noise_level, length_scale, marker=\"x\", zorder=20)\n",
    "    plt.xlabel('Noise Level')\n",
    "    plt.ylabel('Length Scale')\n",
    "    plt.title('Marginal Likelihood Landscape')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "     # Define test data\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    X_test = np.linspace(-3, 3, 60).reshape(-1, 1)\n",
    "    Y_true_f = underlying_function(X_test)\n",
    "    # Create Gaussian Process Regressor\n",
    "    rbf_kernel = kernel(length_scale, sigma_f=1)\n",
    "    gp = GaussianProcessRegressor(kernel=rbf_kernel, sigma_noise=noise_level)\n",
    "\n",
    "    # Fit the model\n",
    "    gp.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_mean, y_pred_std = gp.predict(X_test)\n",
    "\n",
    "    data = np.concatenate([X_train, y_train], axis=1)\n",
    "    df_train = pd.DataFrame(data, columns=['X', 'Y'])\n",
    "\n",
    "    data = np.concatenate([X_test, y_pred_mean.reshape(-1, 1), (y_pred_mean - y_pred_std).reshape(-1, 1), (y_pred_mean + y_pred_std).reshape(-1, 1)], axis=1)\n",
    "    df_pred = pd.DataFrame(data, columns=['X', 'Predicted Mean', 'Lower Bound', 'Upper Bound'])\n",
    "\n",
    "    # Plot the results using Seaborn\n",
    "    sn.scatterplot(x='X', y='Y', data=df_train, color='black', label='Training Data')\n",
    "    sn.lineplot(x='X', y='Predicted Mean', data=df_pred, color='blue', label='Predicted Mean')\n",
    "    plt.fill_between(df_pred['X'], df_pred['Lower Bound'], df_pred['Upper Bound'], color='black', alpha=0.2, label='Uncertainty')\n",
    "    plt.plot(X_test, Y_true_f)\n",
    "    plt.xlim((-3, 3))\n",
    "    plt.ylim((-2,2))\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title('Gaussian Process Regression')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dad65f62",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <script>\n",
       "            function code_toggle_858064647561795776() {\n",
       "                $('div.cell.code_cell.rendered.selected').next().find('div.input').toggle();\n",
       "            }\n",
       "\n",
       "            $('div.cell.code_cell.rendered.selected').find(\"div.input\").hide();\n",
       "        </script>\n",
       "\n",
       "        <a href=\"javascript:code_toggle_858064647561795776()\">Toggle show/hide next cell</a>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hide_toggle(for_next=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b04ae95",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2b255e3fb24473aff5f849b29d5c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.58, description='$l_s$', layout=Layout(width='50%'), max=1.0, min=0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'handle_color': 'white', \"value\":\"white\"}\n",
    "widget = interact(plot_marginal_likelihood_at_location,\n",
    "         length_scale=FloatSlider(value=0.58, min=0.1, max=1, step=0.1, description='$l_s$', layout=Layout(width='50%'), style= style),\n",
    "        noise_level=FloatSlider(value=0.32, min=1e-6, max=1, step=0.1, description='$\\sigma_{\\nu}^2$', layout=Layout(width='50%'), style= style))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5eef71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Difficulties\n",
    "\n",
    "- Presents a $\\mathcal{O}(n^3)$ computational cost and $\\mathcal{O}(n^2)$ in memory.\n",
    "    - Sparse approximation.\n",
    "    \n",
    "- Challenging in high number of dimensions.\n",
    "    - Structural assumptions\n",
    "    \n",
    "- The marginal likelihood is often multi-modal, i.e, local optima.\n",
    "    -  Random start points, using prior distributions, marginalise over hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162483f0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# RISE configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dac24429",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "tmp = cm.update(\n",
    "        \"rise\",\n",
    "        {\n",
    "            \"theme\": \"simple\",\n",
    "            \"transition\": \"fade\",\n",
    "            \"start_slideshow_at\": \"selected\",\n",
    "            \"autolaunch\": True,\n",
    "            \"width\": \"100%\",\n",
    "            \"height\": \"100%\",\n",
    "            \"header\": \"\",\n",
    "            \"footer\":\"\",\n",
    "            \"scroll\": True,\n",
    "            \"enable_chalkboard\": True,\n",
    "            \"slideNumber\": True,\n",
    "            \"center\": False,\n",
    "            \"controlsLayout\": \"edges\",\n",
    "            \"slideNumber\": True,\n",
    "            \"hash\": True,\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "livereveal": {
   "autolaunch": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
